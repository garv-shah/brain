<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="This section of the Algorithmics SAT focuses improving the original data model and algorithm to solve the original problem more efficiently and effectively."><meta property="og:title" content="Algorithmics SAT - Friendship Network Part 3"><meta property="og:description" content="This section of the Algorithmics SAT focuses improving the original data model and algorithm to solve the original problem more efficiently and effectively."><meta property="og:type" content="website"><meta property="og:image" content="https://quartz.jzhao.xyz/icon.png"><meta property="og:url" content="https://quartz.jzhao.xyz/notes/School-Subjects/Algorithmics/SAT/Part-3/Algorithmics-SAT-Part-3/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="Algorithmics SAT - Friendship Network Part 3"><meta name=twitter:description content="This section of the Algorithmics SAT focuses improving the original data model and algorithm to solve the original problem more efficiently and effectively."><meta name=twitter:image content="https://quartz.jzhao.xyz/icon.png"><title>Algorithmics SAT - Friendship Network Part 3</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://quartz.jzhao.xyz//icon.png><link href=https://quartz.jzhao.xyz/styles.f8783aeb83f6dafe71465d8b7c8025c9.min.css rel=stylesheet><link href=https://quartz.jzhao.xyz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://quartz.jzhao.xyz/js/darkmode.63d6a3e095d0bd2b935b62adec9dc11b.min.js></script>
<script src=https://quartz.jzhao.xyz/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://quartz.jzhao.xyz/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://quartz.jzhao.xyz/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://quartz.jzhao.xyz/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://quartz.jzhao.xyz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://quartz.jzhao.xyz/",fetchData=Promise.all([fetch("https://quartz.jzhao.xyz/indices/linkIndex.ea8c34a0dacf5f7a36972f15d71e6b74.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://quartz.jzhao.xyz/indices/contentIndex.040098e98e52d9fd1abf5ab3a255abe2.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://quartz.jzhao.xyz",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://quartz.jzhao.xyz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/quartz.jzhao.xyz\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=quartz.jzhao.xyz src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://quartz.jzhao.xyz/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://quartz.jzhao.xyz/>ðŸ‘‹ Garv's Notes</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Algorithmics SAT - Friendship Network Part 3</h1><p class=meta>Last updated
Aug 26, 2023
<a href=https://github.com/garv-shah/notes/tree/hugo/content/notes/School%20Subjects/Algorithmics/SAT/Part%203/Algorithmics%20SAT%20Part%203.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#suggested-improvements>Suggested Improvements</a><ol><li><a href=#improving-dijkstras-implementation>Improving Dijkstra&rsquo;s Implementation</a></li><li><a href=#improving-distance-function>Improving Distance Function</a></li><li><a href=#improving-held-karp-implementation>Improving Held-Karp Implementation</a></li></ol></li><li><a href=#practicalities-of-an-exact-algorithm>Practicalities of an Exact Algorithm</a><ol><li><a href=#tractability>Tractability</a></li></ol></li><li><a href=#approximateheuristic-algorithms>Approximate/Heuristic Algorithms</a><ol><li><a href=#nearest-neighbour-heuristic>Nearest Neighbour Heuristic</a></li><li><a href=#pairwise-exchange>Pairwise Exchange</a></li><li><a href=#simulated-annealing>Simulated Annealing</a></li></ol></li><li><a href=#final-solution>Final Solution</a><ol><li><a href=#comparison-of-solutions>Comparison of Solutions</a></li><li><a href=#tractability--implications>Tractability & Implications</a></li></ol></li><li><a href=#appendix>Appendix</a><ol><li><a href=#initial-pseudocode>Initial Pseudocode</a></li><li><a href=#modified-exact-algorithm-pseudocode>Modified Exact Algorithm Pseudocode</a></li><li><a href=#approximate-algorithm-pseudocode>Approximate Algorithm Pseudocode</a></li></ol></li></ol></nav></details></aside><p>This section of the Algorithmics SAT focuses improving the original data model and algorithm to solve the original problem more efficiently and effectively.</p><p>Throughout the analysis, note the following variables are used as shorthand:</p><p>Let $F =$ number of friends</p><p>Let $L =$ number of landmarks</p><p>Let $R =$ number of routes</p><p>\newpage</p><a href=#suggested-improvements><h2 id=suggested-improvements><span class=hanchor arialabel=Anchor># </span>Suggested Improvements</h2></a><p>From Part 2, there were various possible optimisations that became evident from the time complexity analysis. These read as follows:</p><ol><li><p>The
<a rel=noopener class="internal-link broken" data-src=#dijkstras>current implementation of Dijkstra&rsquo;s</a> is far from optimal: the current algorithm has a cubic time complexity but with a min priority queue this can supposedly be reduced to $O(L+R\log{L})$.</p></li><li><p>The abstraction of
<a rel=noopener class="internal-link broken" data-src=#distance-function><code>soonest_time_at_node</code></a> can be implemented as a dictionary that is accessed in constant time but is currently implemented as two for loops that makes the
<a rel=noopener class="internal-link broken" data-src=#distance-function><code>dist</code></a> function more complex than necessary.</p></li><li><p>The biggest optimisation needed is the caching of the Held-Karp outputs, meaning that subpaths are calculated once only, and all subsequent subpaths will be read in $O(1)$ time (basically dynamic programming by definition). This should probably help the factorial time complexity, though it might be hindered by the fact that a different starting time means that the whole sub-path is different which decreases how effective this optimisation is.</p></li><li><p>Finally, it may be worth considering approximate solutions. This being said, the scope of the problem to solve does <em>just</em> fit into the practical input sizes that the algorithm allows, but definitely limits its usefulness and real world use cases. In many times, the <em>best</em> solution is not needed, just a relatively good one.</p></li></ol><p>The first three can be implemented and compared relatively easily, so they will be the focus of this section.</p><a href=#improving-dijkstras-implementation><h3 id=improving-dijkstras-implementation><span class=hanchor arialabel=Anchor># </span>Improving Dijkstra&rsquo;s Implementation</h3></a><p>As stated above, the
<a rel=noopener class="internal-link broken" data-src=#dijkstras>current implementation of Dijkstra&rsquo;s</a> is naÃ¯ve because each iteration of the while loop requires a scan over all edges to find the one with the minimum distance, but the relatively small change of using a
<a rel=noopener class="internal-link broken" data-src=#heaps>heap</a> as a min priority queue allows us to find the edge with minimum distance faster. In terms of the
<a rel=noopener class="internal-link broken" data-src=#dijkstras>pseudocode</a>, this just means turning <code>unexplored_list</code> into a min priority queue, where the priority is based on the distance to the node.</p><p>Note that even though the <code>unexplored_list</code> simply appears as a priority queue in the pseudocode, for this change to be beneficial the priority queue data structure must itself be implemented efficiently, using something like a
<a rel=noopener class="internal-link broken" data-src=#heaps>heap</a>.</p><p>See the
<a rel=noopener class="internal-link broken" data-src=#dijkstras-1>modified version of Dijkstra&rsquo;s</a> for the pseudocode.</p><a href=#heaps><h4 id=heaps><span class=hanchor arialabel=Anchor># </span>Heaps</h4></a><p>In most implementations (such as the Python implementation we will be testing with), the inner workings of how a min priority queue works will be abstracted and hence doesn&rsquo;t <em>need</em> to be worried about. Nonetheless, it is worth exploring how they are actually implemented, a popular method being min heaps!</p><p>A heap is a special tree-based data structure in which the tree is a complete binary tree. In other words, each node has exactly two children and every level will be completely filled, except possibly the deepest level. In a min heap, the parent nodes are always smaller than their children, meaning that the root node is the very smallest element.</p><p>Interestingly, since there are no gaps in the tree, the heap can actually be stored simply as an array with additional logic for adding and removing from the priority queue.</p><p><img src=https://quartz.jzhao.xyz//complete_binary_tree.svg width=auto alt="Complete Binary Tree" title="Complete Binary Tree"></p><a href=#insertion><h5 id=insertion><span class=hanchor arialabel=Anchor># </span>Insertion</h5></a><p>When inserting an element, it goes in the next empty spot looking top to bottom, left to right. If that&rsquo;s not where the element should actually go, we can &ldquo;bubble it up&rdquo; until it is, meaning that we can swap that element with its parent node repeatedly until it has gone up the tree enough to be in the correct position. Since it is a binary tree, we can do this in $O(\log{n})$ time.</p><a href=#deletion><h5 id=deletion><span class=hanchor arialabel=Anchor># </span>Deletion</h5></a><p>Since we would want to remove the smallest node, this would of course be the root node. Removing the root node would create an empty spot, so when we remove the root, we instead fill that with the last element added. Similar to above, since this element might not be in the right spot, we take that element and &ldquo;bubble it down&rdquo; until it is, this time swapping with the smaller of the two children repeatedly. Similar to above, we can do this in $O(\log{n})$ time.</p><a href=#improvement><h4 id=improvement><span class=hanchor arialabel=Anchor># </span>Improvement</h4></a><table><thead><tr><th>Visit Set Size</th><th>Initial Algorithm (s)</th><th>Improved Dijkstra&rsquo;s (s)</th></tr></thead><tbody><tr><td>8</td><td>1.4038</td><td>1.2842</td></tr><tr><td>9</td><td>3.9718</td><td>3.9315</td></tr></tbody></table><p>All times are the average of 10 trials. Evidently, the improvement is slight, if any improvement at all.</p><a href=#improving-distance-function><h3 id=improving-distance-function><span class=hanchor arialabel=Anchor># </span>Improving Distance Function</h3></a><p>To find the
<a rel=noopener class="internal-link broken" data-src=#distance-function><code>soonest_time_at_node</code></a>, the original Pythonic implementation was using a nested for loop to find when the next train/bus would arrive. This is thoroughly inefficient, namely due to the amount of times that the
<a rel=noopener class="internal-link broken" data-src=#distance-function><code>dist</code></a> function is called, meaning that there would be a lot of overlap. This <em>could</em> be improved using dynamic programming, but since there is a fixed amount of time in a day (24 hours), it doesn&rsquo;t actually take that long to precompute this waiting time and store it along with the rest of our data. The pseudocode for this function is below:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>time_data = dictionary of dictionaries
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>for line in line_data:
</span></span><span class=line><span class=cl>	for start_node in line_data[line][&#39;timetable&#39;]:
</span></span><span class=line><span class=cl>		for current_time in every minute of a day:
</span></span><span class=line><span class=cl>			// calculate next time at node
</span></span><span class=line><span class=cl>			for arrival_time at start_node:
</span></span><span class=line><span class=cl>				if arrival_time &gt;= current_time and is first:
</span></span><span class=line><span class=cl>					next_time = arrival_time
</span></span><span class=line><span class=cl>			
</span></span><span class=line><span class=cl>			wait_time = next_time - current_time
</span></span><span class=line><span class=cl>			add wait_time to time_date
</span></span></code></pre></td></tr></table></div></div><p>This produces a rather large dictionary of wait times, but the change to $O(1)$ time complexity pays off, even if space complexity is sacrificed.</p><a href=#improvement-1><h4 id=improvement-1><span class=hanchor arialabel=Anchor># </span>Improvement</h4></a><table><thead><tr><th>Visit Set Size</th><th>Initial Algorithm (s)</th><th>Improved Dijkstra&rsquo;s (s)</th><th>Improved Dist (s)</th></tr></thead><tbody><tr><td>8</td><td>1.4038</td><td>1.2842</td><td>0.2746</td></tr><tr><td>9</td><td>3.9718</td><td>3.9315</td><td>2.2123</td></tr><tr><td>10</td><td>27.8881</td><td></td><td>24.4954</td></tr></tbody></table><p>All times are the average of 10 trials and improvements are cumulative. The improvement seems quite large for smaller visit set sizes, but evidently this does not influence the Big O much as $\lim n \rightarrow \infty$.</p><a href=#improving-held-karp-implementation><h3 id=improving-held-karp-implementation><span class=hanchor arialabel=Anchor># </span>Improving Held-Karp Implementation</h3></a><p>Maybe the biggest flaw in the initial algorithm is that
<a rel=noopener class="internal-link broken" data-src=#held-karp>Held-Karp</a> did not use dynamic programming. Due to the way Held-Karp works (explained previously), there are many overlapping problems and without the caching of these outputs, they will be calculated repeatedly unnecessarily. Since this main function is what contributes to the majority of the time complexity, improving it should make the algorithm scale better.</p><p>As we did with Dijkstra&rsquo;s in Part 1, caching can be done with an intermediary function, <code>fetch_hk</code>, which only runs <code>held_karp</code> if the value hasn&rsquo;t already been stored.</p><p>The pseudocode for this process is relatively simple and
<a rel=noopener class="internal-link broken" data-src=#fetch-held-karp-cached>can be found below</a>.</p><a href=#improvement-2><h4 id=improvement-2><span class=hanchor arialabel=Anchor># </span>Improvement</h4></a><table><thead><tr><th>Visit Set Size</th><th>Initial Algorithm (s)</th><th>Improved Dijkstra&rsquo;s (s)</th><th>Improved Dist (s)</th><th>Improved Held-Karp (s)</th></tr></thead><tbody><tr><td>8</td><td>1.4038</td><td>1.2842</td><td>0.2746</td><td>0.0264</td></tr><tr><td>9</td><td>3.9718</td><td>3.9315</td><td>2.2123</td><td>0.0579</td></tr><tr><td>10</td><td>27.8881</td><td></td><td>24.4954</td><td>0.1460</td></tr><tr><td>11</td><td></td><td></td><td></td><td>0.2339</td></tr><tr><td>12</td><td></td><td></td><td></td><td>0.5172</td></tr><tr><td>13</td><td></td><td></td><td></td><td>1.2122</td></tr><tr><td>14</td><td></td><td></td><td></td><td>2.8075</td></tr></tbody></table><p>All times are the average of 10 trials and improvements are cumulative. The improvement from this change is much better than the previous changes, likely changing our Big O time from factorial to exponential, as seen by the roughly doubling running times. This can be verified by creating a line of best fit from the data above, which works out to be $t(n) \approx a^{n-b}$ where $a=2.29792$ and $b=12.7609$. This has an $R^{2}$ value of $0.9996$, which provides us with a relatively high confidence that the new algorithm has $\Theta(2^{n})$. According to this line of best fit, $n=20$ would take about 7 minutes and 53 seconds, while $n=30$ would take almost 3 weeks.</p><p>It is worth noting that although this does improve the time complexity by a large factor, the cache also takes up a lot of space, making the space complexity worse. This tradeoff is quite good in most cases since modern devices have plenty of memory and storage, but in the case that space complexity is a constraint, this may be an unideal optimisation.</p><p>\newpage</p><a href=#practicalities-of-an-exact-algorithm><h2 id=practicalities-of-an-exact-algorithm><span class=hanchor arialabel=Anchor># </span>Practicalities of an Exact Algorithm</h2></a><p>Though the algorithm has seen a dramatic improvement from factorial time to likely exponential time, it still maintains a lot of the issues that the previous version possessed. Namely, because exponential time still does not scale very well, the practical input size for $n$ is still very limited, changing from about $n\leq 9$ to $n \leq 14$.</p><p>As stated in Part 2, this is mostly sufficient for the specific use case of the problem outlined in most cases since the amount of friends people would hang out with in this fashion is intrinsically small, as it only applies itself to close friends. Because of this, even if someone does have a large amount of close friends, it is unlikely that the visit set that gets computed is larger than 14 (the current input data has 18 friends but a visit set of size 7). As such, for the practical cases of this specific problem, the exact algorithm is sufficient, and also works for adjacent scenarios such as mapping applications (Google Maps, etc.) wanting to have certain pickup points along the way.</p><p>The algorithm begins to become impractical once the problem is scaled up more as a general solution for the TSP. For example, if a truck driver for a logistics company wanted an optimal route given a list of pickup points, this would very quickly surpass the practical limit of $n \leq 14$, and the graph would be much larger as well. In wider applications like this, using an exact algorithm is simply not useful, and we would rather want paths that have a &ldquo;small enough&rdquo; cost but have a feasible time complexity. This is where we get into the realm of
<a rel=noopener class="internal-link broken" data-src=#approximateheuristic-algorithms>approximate algorithms</a>.</p><a href=#tractability><h3 id=tractability><span class=hanchor arialabel=Anchor># </span>Tractability</h3></a><p>It is important to note that the problem that was initially described can simply be generalised as the Travelling Salesman Problem, which is famously NP-Hard meaning that there is no known polynomial time solution for the problem.</p><p>Due to the fact that our final exact algorithm implementation had its execution time double every time $n$ was increased by 1, it is safe to assume that the algorithm runs in exponential time at best, meaning that it is still considerably intractable for large inputs due to the exponential growth.</p><p>From this, it is clear that the problem does not become tractable based on the above implementation, and it will be hard to make an exact algorithm that is much faster. This is why
<a rel=noopener class="internal-link broken" data-src=#approximateheuristic-algorithms>approximate algorithms</a> are worth considering, namely those that have performance guarantees of worst cases that are within a certain factor of the minimal cost solution. They provide a trade-off between speed and optimality, and while they make the problem more tractable than exact algorithms, they do not make it completely tractable due to their approximate nature and how they do not always produce the optimal solution.</p><a href=#approximateheuristic-algorithms><h2 id=approximateheuristic-algorithms><span class=hanchor arialabel=Anchor># </span>Approximate/Heuristic Algorithms</h2></a><p>The general idea of most approximation algorithms is we can start with an initial candidate solution and then keep making changes to see if we can get better. The initial candidate solution need not be good, but it would certainly help produce results closer to the global optimum after a certain amount of iterations.</p><p>One of the most intuitive ideas to generate an initial candidate solution would be to visit the closest node in the visit set from any given node, and this can more formally be described as the
<a rel=noopener class="internal-link broken" data-src=#nearest-neighbour-heuristic>Nearest Neighbour Heuristic</a>.</p><a href=#nearest-neighbour-heuristic><h3 id=nearest-neighbour-heuristic><span class=hanchor arialabel=Anchor># </span>Nearest Neighbour Heuristic</h3></a><p>The Nearest Neighbour (NN) algorithm is a greedy (and somewhat naÃ¯ve) approach where the closest unvisited city is selected as the next destination. This method produces a reasonably short route, but usually not the optimal one. The informal steps of this approximate algorithm are listed below:</p><ol><li><p>Mark every vertex as unvisited.</p></li><li><p>Set the starting vertex as the current vertex <strong>u</strong>, marking it as visited.</p></li><li><p>Find the shortest outgoing edge from <strong>u</strong> to an unvisited vertex <strong>v</strong>.</p></li><li><p>Set <strong>v</strong> as the current vertex <strong>u</strong> and mark it as visited.</p></li><li><p>If all vertices have been visited, terminate, if not, go to step 3.</p></li></ol><p>This is a very simple algorithm, but as is the case with most greedy approaches, it can quite easily miss shorter routes. For this specific use case step 3 may cause a few issues in terms of time complexity, as unlike the normal TSP, our graph is not complete. This means that at this step, we would need to run Dijkstra&rsquo;s at every single node in the graph and then sort them to find the shortest path, which is inefficient.</p><p>To make this slightly faster we <em>could</em> simply choose the first unvisited node in the visit set to go to, but that would still require Dijkstra&rsquo;s to run at every node to find a path, meaning that only the time spent sorting would be saved (which is minimal since Dijkstra&rsquo;s will already have them sorted from the min heap). The problem with this approach is that it will produce a less optimal solution, causing the algorithm to have to spend a longer amount of time improving the solution in the simulated annealing phase. This means that it is a bit of a tradeoff, and for now the shortest node will be chosen.</p><p>To avoid using Dijkstra&rsquo;s at all, it is worth considering candidate solutions based on the MST, such as those created by Christofides&rsquo; Algorithm, which may turn out to be faster. This can be further considered to optimise the algorithm, but for simplicity&rsquo;s sake, the NN Heuristic will be continued with.</p><p>Below is the pseudocode to generate an initial candidate solution. Note that in this pseudocode, <code>fetch_djk</code> only has the input of the starting node and visit set and returns the path to the closest node in the visit set, so it is a slightly modified version of the <code>fetch_djk</code> outlined above.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>// creates a canditate solution using the NN Heuristic
</span></span><span class=line><span class=cl>function canditate_solution (
</span></span><span class=line><span class=cl>	start: node, 
</span></span><span class=line><span class=cl>	end: node,
</span></span><span class=line><span class=cl>	visit: set of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime,
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	path = [start]
</span></span><span class=line><span class=cl>	current_vertex = start
</span></span><span class=line><span class=cl>	cost = 0
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	while len(visit) != 0:
</span></span><span class=line><span class=cl>		closest_node = fetch_djk(current_vertex, visit, current_time)
</span></span><span class=line><span class=cl>		path.add(closest_node)
</span></span><span class=line><span class=cl>		cost += closest_node.cost
</span></span><span class=line><span class=cl>		visit.remove(closest_node)
</span></span><span class=line><span class=cl>		current_vertex = closest_node
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	// go back to the end node
</span></span><span class=line><span class=cl>	closest_node = fetch_djk(current_vertex, end, current_time)
</span></span><span class=line><span class=cl>	path.add(closest_node)
</span></span><span class=line><span class=cl>	cost += closest_node.cost
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return {&#39;path&#39;: path, &#39;cost&#39;: cost}
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#pairwise-exchange><h3 id=pairwise-exchange><span class=hanchor arialabel=Anchor># </span>Pairwise Exchange</h3></a><p>Once we have an initial candidate solution that has a reasonable cost for the traversal, a natural question to ask is &ldquo;how can we make it better?&rdquo; More specifically, it is worth considering how we could make modifications to generate a better solution.</p><p>One way to do this is random swapping, where we randomly pick two cities in the current tour order, and swap them. The goal is to see if these random swaps will ever create a lower cost tour, and if they do, we can accept the new solution. This is a form of the Hill Climbing heuristic, where we keep moving around the sample space to see if we can improve our solution at all.</p><p>A slightly more sophisticated technique than randomly swapping the nodes is a method called Pairwise Exchange or 2-opt. The main idea is that we can select any two edges and reconfigure them in the only other way possible with the hopes that this may result in a lower cost tour.</p><p><img src=https://quartz.jzhao.xyz//2-opt.png width=auto alt="Demonstration of the 2-opt Technique" title="Demonstration of the 2-opt Technique">{ height=360px }</p><p>For example, in the diagram above, it can be seen that the pairs $b-e$ and $c-f$ cross over each other, so the edges can be swapped so that they do not.</p><p>More simply, when imagined as a one dimensional array, this could be viewed as the following transformation where we simply reversed the order of the path $e \leftrightarrow d \leftrightarrow c$:</p><ol><li>$a \leftrightarrow \mathbf{b \leftrightarrow e} \leftrightarrow d \leftrightarrow \mathbf{c \leftrightarrow f} \leftrightarrow g$</li><li>$a \leftrightarrow \mathbf{b \leftrightarrow c} \leftrightarrow d \leftrightarrow \mathbf{e \leftrightarrow f} \leftrightarrow g$</li></ol><p>In essence, this &ldquo;untangles&rdquo; our candidate solution and can go through all the possible edge combinations much faster than simply randomly switching nodes (which has a much lower chance of being any better).</p><p>It is worth noting that the 2-opt technique (where 2 edges are selected and reconfigured) can actually be extended to any number of edges, known as <em>k</em>-opt for $k$ edges. It might be worth working with a larger amount of edges (3-opt for example), but for simplicity&rsquo;s sake, 2-opt will the one continued with.</p><p>The above notion of reversing the order of a certain path can be expanded upon to develop our pseudocode. The informal steps for this process are listed below:</p><p>Let $u$ and $v$ be the first vertices of the edges that are to be swapped.
Let $\textrm{tour}$ be an array of vertices that defines our candidate path.</p><ol><li>Add all vertices up to and including $u$ in order.</li><li>Add all vertices after $u$ up to and including $v$ in reverse order.</li><li>Add all vertices after $v$ in order.</li></ol><p>In the example above, $u$ would have been $b$ and $v$ would have been $c$.</p><p>This basic logic can be combined with the Hill Climbing Heuristic to provide a simple way to improve the initial candidate solution. Here, the <code>calculate_cost</code> function would simply add up the cost of traversing the graph in the input order, using Dijkstra&rsquo;s at every vertex.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function pairwise_swap (
</span></span><span class=line><span class=cl>	u: integer,
</span></span><span class=line><span class=cl>	v: integer,
</span></span><span class=line><span class=cl>	path: path of nodes
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	new_tour = []
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	for i in [0, u]:
</span></span><span class=line><span class=cl>		new_tour.add(path[i])
</span></span><span class=line><span class=cl>	for i in [v, u):
</span></span><span class=line><span class=cl>		new_tour.add(path[i])
</span></span><span class=line><span class=cl>	for i in (v, len(path)]:
</span></span><span class=line><span class=cl>		new_tour.add(path[i])
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return new_tour
</span></span><span class=line><span class=cl>end function
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>function calculate_cost (
</span></span><span class=line><span class=cl>	path: path of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	cost = 0
</span></span><span class=line><span class=cl>	time = current_time
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	for i from 0 to len(path) - 1:
</span></span><span class=line><span class=cl>		djk = fetch_djk(path[i], path[i + 1], current_time)
</span></span><span class=line><span class=cl>		cost += djk[&#39;cost&#39;]
</span></span><span class=line><span class=cl>		time += djk[&#39;cost&#39;] number of minutes
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return cost
</span></span><span class=line><span class=cl>end function
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>function hill_climbing (
</span></span><span class=line><span class=cl>	candidate: path of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime,
</span></span><span class=line><span class=cl>	fail_count: int = 0
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	if fail_count &lt; 200:
</span></span><span class=line><span class=cl>		cost = calculate_cost(candidate, current_time)
</span></span><span class=line><span class=cl>		u = random number from 1 to len(candidate) - 1 inclusive
</span></span><span class=line><span class=cl>		v = random number from u to len(candidate) - 1 inclusive
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		new_tour = pairwise_swap(u, v, candidate)
</span></span><span class=line><span class=cl>		new_cost = calculate_cost(new_tour, current_time)
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		if new_cost &lt;= cost:
</span></span><span class=line><span class=cl>			// new cost is better/equal -&gt; accept
</span></span><span class=line><span class=cl>			return hill_climbing(new_tour, current_time, 0)
</span></span><span class=line><span class=cl>		else:
</span></span><span class=line><span class=cl>			// new cost is worse -&gt; go again
</span></span><span class=line><span class=cl>			return hill_climbing(candidate, current_time, fail_count + 1)
</span></span><span class=line><span class=cl>	else:
</span></span><span class=line><span class=cl>		return candidate
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><p>Note that the above range of $u$ and $v$ values has been chosen to prevent them from referring to the start or end of the tour, since in our particular use case we would like to force the tour to start and end at particular locations</p><a href=#simulated-annealing><h3 id=simulated-annealing><span class=hanchor arialabel=Anchor># </span>Simulated Annealing</h3></a><p>One of the problems with the above solution is that it will quite easily get stuck on a local minimum. Demonstrated by the graph below, the Hill Climbing Heuristic is blind to anything besides its local vicinity. As such, there may be an overall better solution, but not one that can be achieved by constantly improving the current candidate solution. In other words, sometimes things have to get worse before they get better, especially for the TSP.</p><p><img src=https://quartz.jzhao.xyz//Local%20Minima%20Example.png width=auto alt="Example of the Limitations of Hill Climbing" title="Example of the Limitations of Hill Climbing"></p><p>Currently, once the Hill Climbing algorithm is implemented in Python, it produces a somewhat suboptimal result. It is hardcoded to terminate after it has had 200 consecutive iterations that have seen no improvement. Sometimes, it can terminate on a relatively good result, but in other cases it gets stuck on much more sub-par candidates. This can be demonstrated by the two paths bellow, both of which the Hill Climbing algorithm terminated on.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>The cost has been improved from 234.0 to 227.0
</span></span><span class=line><span class=cl>[&#39;Brandon Park&#39;, &#39;Oakleigh&#39;, &#39;Wheelers Hill Library&#39;, &#39;CGS WH&#39;, &#39;Chadstone&#39;, &#39;Caulfield&#39;, &#39;Flinders Street&#39;, &#39;Camberwell&#39;, &#39;Parliament&#39;, &#39;Melbourne Central&#39;, &#39;Brighton Beach&#39;, &#39;Richmond&#39;, &#39;Mount Waverley&#39;, &#39;Glen Waverley&#39;, &#39;Brandon Park&#39;]
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>The cost has been improved from 277.0 to 270.0
</span></span><span class=line><span class=cl>[&#39;Brandon Park&#39;, &#39;CGS WH&#39;, &#39;Glen Waverley&#39;, &#39;Mount Waverley&#39;, &#39;Camberwell&#39;, &#39;Chadstone&#39;, &#39;Caulfield&#39;, &#39;Brighton Beach&#39;, &#39;Flinders Street&#39;, &#39;Melbourne Central&#39;, &#39;Parliament&#39;, &#39;Richmond&#39;, &#39;Oakleigh&#39;, &#39;Wheelers Hill Library&#39;, &#39;Brandon Park&#39;]
</span></span></code></pre></td></tr></table></div></div><p>Simulated Annealing is a concept that builds off of this idea of possibly selecting a worse solution to hopefully get to the global optimum. Namely, it tries to explore as much of the search space as possible at the start (by being more likely to select worse candidates) and then gradually reduces this chance so that it can converge on a better solution.</p><p>The logic behind this is quite similar to Hill Climbing:</p><ol><li><p>Start with a candidate solution, from a previous algorithm or just a random tour.</p></li><li><p>Modify this candidate by trying to apply some tour improvements, in this case 2-opt.</p></li><li><p>Decide whether to accept the new solution or stay with the old one.</p></li></ol><p>The key difference here is step 3. In both algorithms, if the new tour&rsquo;s cost is lower than the previous one, we will always accept it. If the cost is more than the current solution, with some probability, we will actually accept the higher cost solution but this probability will decrease over time.</p><p>How this probability is determined is mostly based on a parameter called the &ldquo;Temperature&rdquo; $T$. At the start we will initialise this to a high value, and a higher temperature means we are more likely to select a worse solution. Any $T \in [0, 1]$ will work, but we want to gradually reduce our temperature over time, so that it can influence some probability function.</p><p>There are usually three main types of temperature reduction functions, where $\alpha$ is the factor by which the temperature is scaled after $n$ iterations:</p><ol><li><p>Linear Reduction Rule: $T = T - \alpha$</p></li><li><p>Geometric Reduction Rule: $T = T \times \alpha$</p></li><li><p>Slow-Decrease Rule<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>: $T = \frac{T}{1+\beta T}$</p></li></ol><p>Each of these reduction rules decreases the temperature at a different rate, so they may be better for different use cases. For now, we will settle upon the Geometric Reduction Rule (as it is the most common).</p><p>Starting at the initial temperature, the algorithm will loop through $n$ iterations and then decrease the temperature according to the selected temperature reduction function at the end of every iteration. This loop will stop once the terminating condition is reached, generally some low cutoff temperature where we have determined an acceptable amount of the search space has been explored.</p><p>Finally, within each iteration, we will use our temperature, the old cost and the new cost to determine whether we accept the new solution or not. This follows the formula below where $\Delta c = \textrm{new cost} - \textrm{old cost}$:</p><p>$$
P=
\begin{cases}
1 & \Delta c \leq 0 \\ e^{-\beta \Delta c/T} & 0 &lt; \Delta c\\ \end{cases}
$$</p><p>To demonstrate, if the new cost is less than or equal to the old cost, the new cost will always be accepted. If on the other hand the new cost is greater, then we <em>might</em> pick it based on the formula shown above. This equation is inspired by the formula for the energy released by metal particles as they cool down from thermodynamics: $P(\Delta E) = e^{-\frac{\Delta E}{k * t}}$. This process is known as annealing, hence the name of the algorithm! Borrowing this equation from physics turns out to be quite elegant, giving us a probability distribution known as the Boltzman distribution.</p><p>It is worth noting the different parameters that can be tuned, and the effectiveness of the algorithm depends on the choice of these parameters:</p><ol><li><p>$\beta$ - Normalising Constant
The choice of this constant is dependent on the expected variation in the performance measure over the search space, If the chosen value of $\beta$ is higher, the probability of accepting a solution is supposedly also higher in later iterations. In our use case, we can simply play around with this number and see if it changes anything!</p></li><li><p>$T_{0}$ - Initial Temperature
This is simply the temperature we start with, and should be relatively close to one so that we accept a lot of new solutions at the start. For now, we will set $T_{0} = 0.98$.</p></li><li><p>$\alpha$ - Temperature Scaling Factor
As explained above, depending on the temperature reduction function chosen, $\alpha$ will reduce it at a different rate. Low $\alpha$ values restrict the search space faster, so we can choose $\alpha = 0.85$ for now.</p></li></ol><p>The number of iterations before the temperature is updated can also be played around with, for now this will be set to 5. Also, the cutoff terminating temperature can also be set to allow the algorithm to search for longer.</p><p>The above should demonstrate the main weakness of simulated annealing: there are a lot of tunable parameters that vastly influence the performance of the algorithm. If our input data is very sparse, the algorithm may perform much worse for certain use cases. Nonetheless, it is most definitely an improvement over the Hill Climbing algorithm as it does not increase time complexity or space complexity, but it does provide a more accurate output.</p><p>Below is the pseudocode that summarises the above discussion:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function acceptance_probability (
</span></span><span class=line><span class=cl>	old_cost: number,
</span></span><span class=line><span class=cl>	new_cost: number,
</span></span><span class=line><span class=cl>	beta: number,
</span></span><span class=line><span class=cl>	temp: number
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	c = new_cost - old_cost
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	if c &lt;= 0:
</span></span><span class=line><span class=cl>		return 1
</span></span><span class=line><span class=cl>	else:
</span></span><span class=line><span class=cl>		return e**((-beta * c)/temp)
</span></span><span class=line><span class=cl>end function
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>function simulated_annealing (
</span></span><span class=line><span class=cl>	candidate: path of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime,
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	// parameters to fiddle with
</span></span><span class=line><span class=cl>	temp = 0.98
</span></span><span class=line><span class=cl>	min_temp = 0.00001
</span></span><span class=line><span class=cl>	temp_change = 5
</span></span><span class=line><span class=cl>	beta = 1.2
</span></span><span class=line><span class=cl>	alpha = 0.85
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	old_cost = calculate_cost(candidate, current_time)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	while temp &gt; min_temp:
</span></span><span class=line><span class=cl>		for n from 1 to temp_change:
</span></span><span class=line><span class=cl>			u = random number from 1 to len(candidate) - 1 inclusive
</span></span><span class=line><span class=cl>			v = random number from u to len(candidate) - 1 inclusive
</span></span><span class=line><span class=cl>			
</span></span><span class=line><span class=cl>			new_tour = pairwise_swap(u, v, candidate)
</span></span><span class=line><span class=cl>			new_cost = calculate_cost(new_tour, current_time)
</span></span><span class=line><span class=cl>			
</span></span><span class=line><span class=cl>			ap = acceptance_probability(old_cost, new_cost, beta, temp)
</span></span><span class=line><span class=cl>			
</span></span><span class=line><span class=cl>			if ap &gt; random float from 0 to 1:
</span></span><span class=line><span class=cl>				candidate = new_tour
</span></span><span class=line><span class=cl>				old_cost = new_cost
</span></span><span class=line><span class=cl>			
</span></span><span class=line><span class=cl>		temp *= alpha
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>	return candidate
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#normalising-function><h4 id=normalising-function><span class=hanchor arialabel=Anchor># </span>Normalising Function</h4></a><p>Something that may have become apparent when viewing the above examples is how the paths generated by this approximate solution are somehow much shorter than those generated by Held-Karp. This is due to the fact that the implementation of Held-Karp is not restricted to only visiting each node once, whereas the approximate algorithms are. Due to this, we get some interesting behaviour that needs to be accounted for.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[&#39;Brandon Park&#39;, &#39;Oakleigh&#39;, &#39;CGS WH&#39;, &#39;Wheelers Hill Library&#39;, &#39;Caulfield&#39;, &#39;Flinders Street&#39;, &#39;Melbourne Central&#39;, &#39;Parliament&#39;, &#39;Glen Waverley&#39;, &#39;Chadstone&#39;, &#39;Brighton Beach&#39;, &#39;Camberwell&#39;, &#39;Mount Waverley&#39;, &#39;Richmond&#39;, &#39;Brandon Park&#39;]
</span></span></code></pre></td></tr></table></div></div><p>The above is a path generated by the Hill Climbing algorithm. The issue to note is that it advises the user to go from Glen Waverley to Chadstone, but there is no edge between them for this to happen. Since the algorithms have been using Dijkstra&rsquo;s to go to any other node, it has in essence been treating our tour as a complete graph, even though it is not. As such, the edges in between these locations need to be added in again.</p><p>This is quite simple to do, and is similar to the <code>calculate_cost</code>, except the paths are added instead of the costs.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function normalise_path (
</span></span><span class=line><span class=cl>	path: path of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	return_path = []
</span></span><span class=line><span class=cl>	time = current_time
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	for i from 0 to len(path) - 1:
</span></span><span class=line><span class=cl>		djk = fetch_djk(path[i], path[i + 1], current_time)
</span></span><span class=line><span class=cl>		time += djk[&#39;cost&#39;] number of minutes
</span></span><span class=line><span class=cl>		// this is to prevent the last and first item double up
</span></span><span class=line><span class=cl>		return_path += everything in djk[&#39;path&#39;] except last item
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return_route.add(last item in route)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return cost
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><p>\newpage</p><a href=#final-solution><h2 id=final-solution><span class=hanchor arialabel=Anchor># </span>Final Solution</h2></a><p>The problem these algorithms were set out to solve is a specific application of the TSP: how could the shortest closed walk be found that picks up all my friends as we travel around the city?</p><p>The initial approach to solve this problem used the concepts of dynamic programming to recursively split up the larger problem into smaller overlapping subproblems. Unfortunately, because the number of subpaths increases exponentially as the size of the visit set increased, it was demonstrated that even though an exact algorithm may provide an optimal solution, intractable problems like the TSP may require a better time complexity in a trade-off for accuracy.</p><p>The approaches for the approximate solutions have followed two main phases:</p><ul><li>Generate a possible candidate solution.</li><li>Improve the candidate using some optimisation algorithm.</li></ul><p>The Nearest Neighbour heuristic was used to generate the initial candidate, simply travelling to the closest node remaining in the visit set until a closed walk has been achieved. This was then later improved upon by processing this candidate through both the Hill Climbing and Simulated Annealing algorithms.</p><p>In regard to the performance of Simulated Annealing (SA) vs Hill Climbing (HC), it seems that the output of the former is heavily dependent on the parameters set. Whereas HC produced results in a relatively large range, SA could be tuned to consistently provide the same &ldquo;good&rdquo; results every time or if the parameters were not optimal, a completely rubbish result every time.</p><p>For example, with $T_{0}=0.98, \beta = 4, \alpha = 0.9$ and the 5 iterations before updating the temperature, SA consistently produced a hamiltonian path that would take 254 minutes to traverse. HC was more inconsistent, outputting 274 initially, 281 next and struck gold with the last try with 237. Surprisingly though, the difference between Hill Climbing and Simulated Annealing doesn&rsquo;t seem to be vast for this particular input graph, and SA can simply be viewed as a more tunable and adjustable version of HC to be able to produce a more consistent result.</p><p>When this was changed to simply be the visit set that the friends reside at, the output for both HC and SA was as follows:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Final candidate cost is 143.0
</span></span><span class=line><span class=cl>Final candidate path is [&#39;Brandon Park&#39;, &#39;Wheelers Hill Library&#39;, &#39;CGS WH&#39;, &#39;Glen Waverley&#39;, &#39;Mount Waverley&#39;, &#39;Richmond&#39;, &#39;Camberwell&#39;, &#39;Richmond&#39;, &#39;Flinders Street&#39;, &#39;Caulfield&#39;, &#39;Oakleigh&#39;, &#39;Brandon Park&#39;]
</span></span></code></pre></td></tr></table></div></div><p>Nonetheless, neither of them are able to find the true optimal path that Held-Karp creates:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Final candidate cost is 130.0
</span></span><span class=line><span class=cl>Final candidate path is [&#39;Brandon Park&#39;, &#39;Wheelers Hill Library&#39;, &#39;CGS WH&#39;, &#39;Glen Waverley&#39;, &#39;Mount Waverley&#39;, &#39;Richmond&#39;, &#39;Flinders Street&#39;, &#39;Caulfield&#39;, &#39;Oakleigh&#39;, &#39;Richmond&#39;, &#39;Camberwell&#39;, &#39;Richmond&#39;, &#39;Oakleigh&#39;, &#39;Brandon Park&#39;]
</span></span></code></pre></td></tr></table></div></div><p>This could simply be because 2-opt does not provide the required permutations to be able to reach the optimal path, but still demonstrates the required tradeoff between approximate solutions and exact algorithms, a tradeoff of time vs accuracy.</p><a href=#comparison-of-solutions><h3 id=comparison-of-solutions><span class=hanchor arialabel=Anchor># </span>Comparison of Solutions</h3></a><a href=#design-features><h4 id=design-features><span class=hanchor arialabel=Anchor># </span>Design Features</h4></a><p>As discussed above, Held-Karp (the exact algorithm) used the principle of dynamic programming to split the larger problem into instances of the similar overlapping subproblems that can be solved recursively. By utilising the fact that every subpath of a path of minimum distance is itself of minimum distance, we can recursively reduce the size of the visit set by one and solve for the smaller cases. In this case, due to the TSP&rsquo;s intractability, this only decreases the time complexity from factorial to exponential, saving time by ensuring that subpaths are not re-calculated.</p><p>On the other hand, the combination of algorithms that produce the approximate solutions operate based off a variety of design principles.</p><p>The initial candidate solution generated by the NN Heuristic uses a greedy design pattern to find a possible path. This design pattern does not work with many problems (including the TSP) because sometimes things have to get worse for an overall better result.</p><p><img src=https://quartz.jzhao.xyz//greedy_example.svg width=auto alt="Demonstration of Why Greedy Algorithms Fail" title="Demonstration of Why Greedy Algorithms Fail"></p><p>Demonstrated above, the greedy design feature would select &ldquo;3&rdquo; as it is the best option visible at the time, but will end up selecting a far worse solution that could easily be avoided with some intuition for what comes afterwards.</p><p>Nonetheless, the greedy design pattern in the NN heuristic generally produces a somewhat viable candidate, that is then improved upon by certain Generate and Test algorithms.</p><p>One such algorithm is Hill Climbing, which refers to a type of local search optimisation technique that provides an iterative way to make incremental changes to a candidate and proceed if an improvement has been found.</p><p>Simulated Annealing expands upon this idea by using a probabilistic technique to decide if we accept an incremental change or not. Both these local search algorithms allow for an exploration of adjacent solutions that help find an improved solution in a tractable way.</p><p>The difference between the two approaches and their design patterns lies between the intended output. The dynamic programming approach guarantees a correct output, but since the requirements are slightly different for the approximate algorithms, a wider range of design techniques are available (such as using random probability or the Generate and Test pattern) that can get us closer to a better solution, even if it produces a non-deterministic non-optimal result.</p><a href=#coherence><h4 id=coherence><span class=hanchor arialabel=Anchor># </span>Coherence</h4></a><p>Overall, Held-Karp is far more of a consistent and logical solution. Since the exact algorithm is inherently deterministic, it is always guaranteed to produce the same optimal result consistently. Â In contrast, the NN algorithm&rsquo;s performance can vary widely depending on the arrangement of nodes and both the optimisation algorithms use probability to pick $u$ and $v$ values. Simulated annealing is also non-deterministic ($\because$ probabilistic), meaning that it is nowhere near as consistent as Held-Karp. That being said, Simulated Annealing does seem to converge consistently on the same or similar local optima based on its input parameters, so we can render it more coherent than Hill Climbing but much less so than Held-Karp.</p><p>The influence of this difference in consistency between the two approaches on the real world applications is key to deciding which approach is better. Exact algorithms would be preferred in scenarios where predictability and repeatability are crucial. For example, in scientific research studies on geographical data that is static, the superior coherence of Held-Karp would mean that the study is repeatable and verifiable by peers. On the other hand, the lower consistency of SA and HC are not necessarily disadvantageous in real world applications, because they can provide more flexibility and adaptability. Instead of providing only one solution, they provide many good candidates that the user can consider between. This flexibility would be ideal for larger operations such as a logistics company, where the clients and pickup points are very actively changing, and alternative routes need to be provided in case the algorithm does not account for real world disturbances such as road closures.</p><a href=#fitness-for-problem><h4 id=fitness-for-problem><span class=hanchor arialabel=Anchor># </span>Fitness for Problem</h4></a><p>In terms of fitness for the problem, it would be safe to say that the exact algorithm would be preferred for the initial problem described. Even though Held-Karp would have a larger space complexity (due to all the subpaths that need to be stored), a typical user&rsquo;s phone will have plenty of storage such that space should not be too much of an issue. The inefficient time complexity of the algorithm mostly relates to how it scales to larger visit set sizes, anything below $n=14$ is barely noticeable to the typical user. Since most people will not be intending to travel in this fashion with such a large number of friends, it would likely be preferred to use the exact algorithm as it provides the optimal solution. This being said, Held-Karp is somewhat inflexible, especially when it comes to frequently changing data. As it only provides one path and one path only, it could be a bit of an issue when it does not account for certain data such as a bus replacement (very common around Victoria). As such, it might be best to use a combination of both in an application, defaulting to the modified Held-Karp but switching over to the approximate algorithms once $n>13$ or more solutions are requested.</p><a href=#efficiency--time-complexity><h4 id=efficiency--time-complexity><span class=hanchor arialabel=Anchor># </span>Efficiency & Time Complexity</h4></a><p>As established above, the improved Held-Karp algorithm maintains an exponential time complexity, similar enough to $O(2^{n})$ that we can use this simplified version to come to more clear conclusions.</p><p>Going through the pseudocode for the approximate algorithms, the algorithm to find a candidate solution is run first. In this case, this would be the Nearest Neighbour heuristic, which runs the following code for every node in the visit set (of size $n$)</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>closest_node = fetch_djk(current_vertex, visit, current_time)
</span></span><span class=line><span class=cl>path.add(closest_node)
</span></span><span class=line><span class=cl>cost += closest_node.cost
</span></span><span class=line><span class=cl>visit.remove(closest_node)
</span></span><span class=line><span class=cl>current_vertex = closest_node
</span></span></code></pre></td></tr></table></div></div><p>Since it runs Dijkstra&rsquo;s at every node, our time complexity for NN will just be $n \times \textrm{Dijkstra&rsquo;s Time Complexity}$. If we presume that the above optimisations for Dijkstra were effective then this would be at $O(L+R\log{L})$ (the generally accepted time complexity for Dijkstra&rsquo;s using min heaps), but even if this was not the case, we would have a time complexity of $O(L^{2})$. This provides an NN time complexity of $O(n \times L^{2})$.</p><p>In terms of Hill Climbing, during every iteration $i$, the algorithm runs the following pseudocode:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>cost = calculate_cost(candidate, current_time)
</span></span><span class=line><span class=cl>u = random number from 1 to len(candidate) - 1 inclusive
</span></span><span class=line><span class=cl>v = random number from u to len(candidate) - 1 inclusive
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>new_tour = pairwise_swap(u, v, candidate)
</span></span><span class=line><span class=cl>new_cost = calculate_cost(new_tour, current_time)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>if new_cost &lt;= cost:
</span></span><span class=line><span class=cl>	// new cost is better/equal -&gt; accept
</span></span><span class=line><span class=cl>	Go again with the new tour
</span></span><span class=line><span class=cl>else:
</span></span><span class=line><span class=cl>	// new cost is worse -&gt; go again
</span></span><span class=line><span class=cl>	Go again with the same tour
</span></span></code></pre></td></tr></table></div></div><p>First, the cost of the candidate is evaluated. This requires us to run Dijkstra&rsquo;s on each node in the visit set again, but since the output of Dijkstra&rsquo;s is cached, this would actually only take $O(n)$ time. Next, a pairwise swap is done, which adds every node in the visit set to a new array in a differing order which is also in $O(n)$ time. Finally, the cost is calculated again, leaving us with a final total of $O(3n)$. Overall, this means that this process is done in linear time for $i$ iterations, leaving a final time complexity of $O(i \times n)$.</p><p>Simulated Annealing has the exact same time complexity as Hill Climbing because the only major difference is if a candidate solution is accepted or not and this is done in $O(1)$ time because the time complexity of selecting a random number is $O(1)$.</p><p>This leaves us with a final time complexity of $O(n \times L^{2} + i \times n)$ = $O(n(L^{2}+i))$.</p><a href=#tractability--implications><h3 id=tractability--implications><span class=hanchor arialabel=Anchor># </span>Tractability & Implications</h3></a><p>As discussed above, the time complexity for the exact algorithm is effectively $O(2^{n})$ and the time complexity for the approximate algorithms is $O(n(L^{2}+i))$ where $n$ is the size of the visit set, $L$ is the number of landmarks in the graph overall and $i$ is the amount of times that the optimisation algorithm will iterate. $i$ will typically be a constant and can therefore be ignored and for the same input graph (this assumption was made for the simplification of Held-Karp too) $L^{2}$ will be constant as well.</p><p>In effect, this means that for the same input graph, the time complexities we are looking at are $O(2^{n})$ vs $O(n)$ as the visit set size increases by a constant factor. The vast difference between these two time complexities shows how easily approximate solutions can be derived in polynomial time, which helps make this problem more tractable. Namely, this demonstrates that the problem of finding a solution to the TSP within a set factor of the optimal solution is a tractable one, even if finding the <em>actual</em> optimal solution is not.</p><p>This has many implications for the real world applications of the broader version of this problem. Though the discussion above concluded that the exact algorithm would be superior for the initial specified problem, the tradeoff of lower accuracy for an improved time complexity can be beneficial to many use-cases. Below is a list of applications that would be better suited to either type of algorithm:</p><p><strong>Exact Algorithm</strong>:</p><ul><li>An exact algorithm would be well suited to static non-changing data where time is not much of a concern but the best solution is required. In a scenario where large freeways need to be built to visit a few key cities, the geographical data remains mostly static since the overall terrain does not change suddenly, but an inefficient solution could cost millions. Similarly, in wartime where tunnels and bunker networks need to be built that connect everyone to a few key locations, a few extra kilometres could result in hundreds of lost lives. In cases like this, provided that the number of key locations is sufficiently small, users would likely not mind waiting for a more optimal output.</li></ul><p><strong>Approximate Algorithm</strong>:</p><ul><li>As discussed previously, an approximate algorithm would be very well suited to logistics/trucking companies that have to move a lot of shipments and goods across the country fast. The nature of real world companies means that clients would appear and disappear on a daily basis, and there are always new locations to be delivered to or picked up from. Since the input graph is dynamically changing, an exact solution would be very quickly out of date and an $O(n)$ time complexity would be preferred over the intractable $O(2^{n})$ complexity since the amount of pickup points would simply be so large.</li><li>An approximate algorithm would be well suited to data routing, specifically peer to peer networks that want to connect a large group of people. For example, a P2P video conferencing call would need to find a sufficiently small closed walk to ensure that the call has minimal delay. Since the input data for this case would be constantly changing (people leaving and joining with variable bandwidths), it would need to be run very often, and an intractable solution would not suffice.</li></ul><p>This being said, most applications would be better suited to a combination of both. With a small number of nodes in the visit set, the intractability of finding an exact solution is not much of an issue, as the speeds are virtually instant anyway, but anything above about 15 to 20 nodes will render the computational time to be prohibitive. As such, for most real world applications, it makes more sense to use a combination of both the algorithms and switch over once the input size has exceeded the practical time constraints a layman user would expect. Such is the case with the initial solution, as described above.</p><p>\newpage</p><a href=#appendix><h2 id=appendix><span class=hanchor arialabel=Anchor># </span>Appendix</h2></a><a href=#initial-pseudocode><h3 id=initial-pseudocode><span class=hanchor arialabel=Anchor># </span>Initial Pseudocode</h3></a><p>The following is the final pseudocode reiterated from the previous 2 parts, namely for convenience while analysing, since multiple modifications were made to the initial pseudocode. A Python implementation of this pseudocode can be found
<a href=https://github.com/garv-shah/brain/blob/hugo/content/notes/School-Subjects/Algorithmics/SAT/main_old.py rel=noopener>here</a>.</p><p>Let $A =$ starting vertex
Let $B =$ ending vertex
Let $S = {P, Q, R}$ or any other vertices to be visited along the way.
Let $C \in S$ (random node in $S$)</p><a href=#main-function><h4 id=main-function><span class=hanchor arialabel=Anchor># </span>Main Function</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function main(
</span></span><span class=line><span class=cl>	friends: dictionary,
</span></span><span class=line><span class=cl>	landmarks: dictionary,
</span></span><span class=line><span class=cl>	routes: dictionary,
</span></span><span class=line><span class=cl>	timetable: dictionary
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	// global variable declarations
</span></span><span class=line><span class=cl>	concession: bool = Ask the user &#34;Do you posses a concession card?&#34;
</span></span><span class=line><span class=cl>	holiday: bool = Ask the user &#34;Is today a weekend or a holiday?&#34;
</span></span><span class=line><span class=cl>	user_name: string = Ask the user to select a friend from friends dictionary
</span></span><span class=line><span class=cl>	selected_time = Ask the user what time they are leaving
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	cached_djk: dictionary = empty dictionary
</span></span><span class=line><span class=cl>	edge_lookup_matrix: matrix = |V| x |V| matrix that stores a list of edges in each entry
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	// get distance of all friends from landmarks
</span></span><span class=line><span class=cl>	friend_distances: dictionary = calculate_nodes(friends, landmarks)
</span></span><span class=line><span class=cl>	visit_set: set = set of all closest nodes from friend_distances
</span></span><span class=line><span class=cl>	people_at_nodes: dictionary = all friends sorted into keys of which nodes they are closest to, from visit_set
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	home: string = closest node of user_name
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print all friends, where they live closest to and how far away
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print out friends that would take more than 20 minutes to walk (average human walking speed is 5.1 km/h)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	hamiltonian_path = held_karp(home, home, visit_set, selected_time)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print how much the trip would cost and how long it would take
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print the path of the hamiltonian_path
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#calculate-nodes><h4 id=calculate-nodes><span class=hanchor arialabel=Anchor># </span>Calculate Nodes</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function calculate_nodes (
</span></span><span class=line><span class=cl>	friend_data: dictionary,
</span></span><span class=line><span class=cl>	node_data: dictionary
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	for friend in friend_data:
</span></span><span class=line><span class=cl>		home: tuple = friend[&#39;home&#39;]
</span></span><span class=line><span class=cl>		// initial min vals that will be set to smallest iterated distance
</span></span><span class=line><span class=cl>		min: float = infinity
</span></span><span class=line><span class=cl>		min_node: node = null
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		for node in node_data:
</span></span><span class=line><span class=cl>			location: tuple = node[&#39;coordinates&#39;]
</span></span><span class=line><span class=cl>			// find real life distance (functional abstraction)
</span></span><span class=line><span class=cl>			distance: float = latlong_distance(home, location)
</span></span><span class=line><span class=cl>			if distance &lt; min:
</span></span><span class=line><span class=cl>				min = distance
</span></span><span class=line><span class=cl>				min_node = node
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		distance_dict[friend][&#39;min_node&#39;] = min_node
</span></span><span class=line><span class=cl>		distance_dict[friend][&#39;distance&#39;] = min
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#held-karp><h4 id=held-karp><span class=hanchor arialabel=Anchor># </span>Held-Karp</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function held_karp (
</span></span><span class=line><span class=cl>    start: node,
</span></span><span class=line><span class=cl>    end: node,
</span></span><span class=line><span class=cl>    visit: set&lt;node&gt;,
</span></span><span class=line><span class=cl>    current_time: datetime
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>    if visit.size = 0:
</span></span><span class=line><span class=cl>    	djk = fetch_djk(start, end, current_time)
</span></span><span class=line><span class=cl>		return djk[&#39;cost&#39;]
</span></span><span class=line><span class=cl>    else:
</span></span><span class=line><span class=cl>        min = infinity
</span></span><span class=line><span class=cl>        For node C in set S:
</span></span><span class=line><span class=cl>	        sub_path = held_karp(start, C, (set \ C), current_time)
</span></span><span class=line><span class=cl>	        djk = fetch_djk(C, end, current_time + toMinutes(sub_path[&#39;cost&#39;]))
</span></span><span class=line><span class=cl>	        cost = sub_path[&#39;cost&#39;] + djk[&#39;cost&#39;]
</span></span><span class=line><span class=cl>	        if cost &lt; min:
</span></span><span class=line><span class=cl>	            min = cost
</span></span><span class=line><span class=cl>	    return min
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#dijkstras><h4 id=dijkstras><span class=hanchor arialabel=Anchor># </span>Dijkstra&rsquo;s</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function dijkstras (
</span></span><span class=line><span class=cl>    start: node,
</span></span><span class=line><span class=cl>    current_time: datetime
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>    // Set all node distance to infinity
</span></span><span class=line><span class=cl>    for node in graph:
</span></span><span class=line><span class=cl>        distance[node] = infinity
</span></span><span class=line><span class=cl>        predecessor[node] = null
</span></span><span class=line><span class=cl>        unexplored_list.add(node)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    // starting distance has to be 0
</span></span><span class=line><span class=cl>    distance[start] = 0
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    // while more to still explore
</span></span><span class=line><span class=cl>    while unexplored_list is not empty:
</span></span><span class=line><span class=cl>        min_node = unexplored node with min cost
</span></span><span class=line><span class=cl>        unexplored_list.remove(min_node)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>	    // go through every neighbour and relax
</span></span><span class=line><span class=cl>        for each neighbour of min_node:
</span></span><span class=line><span class=cl>            current_dist = distance[min_node] + dist(min_node, neighbour, current_time + to_minutes(distance[min_node]))
</span></span><span class=line><span class=cl>            // a shorter path has been found to the neighbour -&gt; relax value
</span></span><span class=line><span class=cl>            if current_dist &lt; distance[neighbour]:
</span></span><span class=line><span class=cl>                distance[neighbour] = current_dist
</span></span><span class=line><span class=cl>                predecessor[neighbour] = min_node
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    return {
</span></span><span class=line><span class=cl>	    &#39;distances&#39;: distance,
</span></span><span class=line><span class=cl>	    &#39;predecessors&#39;: predecessor,
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#fetch-dijkstras-cached><h4 id=fetch-dijkstras-cached><span class=hanchor arialabel=Anchor># </span>Fetch Dijkstra&rsquo;s (Cached)</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>cached_djk = dictionary of node -&gt; dict
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>function fetch_djk (
</span></span><span class=line><span class=cl>    start: node,
</span></span><span class=line><span class=cl>    end: node,
</span></span><span class=line><span class=cl>    current_time: datetime,
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	name = start + &#39;@&#39; + current_time
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>    if cached_djk[name] does not exists:
</span></span><span class=line><span class=cl>        cached_djk[name] = dijkstras(start, current_time)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    djk = cached_djk[name]
</span></span><span class=line><span class=cl>    # reconstructs the path  
</span></span><span class=line><span class=cl>    path = [end] as queue
</span></span><span class=line><span class=cl>    while path.back != start:
</span></span><span class=line><span class=cl>        path.enqueue(djk[&#39;predecessors&#39;][path.back])
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    return {
</span></span><span class=line><span class=cl>        &#39;distance&#39;: djk[&#39;distances&#39;][end],
</span></span><span class=line><span class=cl>        &#39;path&#39;: path
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#distance-function><h4 id=distance-function><span class=hanchor arialabel=Anchor># </span>Distance Function</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function dist (
</span></span><span class=line><span class=cl>	start: node,
</span></span><span class=line><span class=cl>	end: node,
</span></span><span class=line><span class=cl>	current_time: datetime
</span></span><span class=line><span class=cl>):	
</span></span><span class=line><span class=cl>	// if the start and end node are the same, it takes no time to get there
</span></span><span class=line><span class=cl>	if start = end:
</span></span><span class=line><span class=cl>		return 0
</span></span><span class=line><span class=cl>	else if edges = null:
</span></span><span class=line><span class=cl>		// if no edge exists between nodes
</span></span><span class=line><span class=cl>		return infinity
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	edges = edge_lookup_matrix[start][end]
</span></span><span class=line><span class=cl>	distances = []
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	// go over each possible edge between nodes (multiple possible)
</span></span><span class=line><span class=cl>	for edge in edges:
</span></span><span class=line><span class=cl>		line = edge.line
</span></span><span class=line><span class=cl>		// next time bus/train will be at node (functional abstraction)
</span></span><span class=line><span class=cl>		next_time = soonest_time_at_node(timetable, line, start, current_time)
</span></span><span class=line><span class=cl>		wait_time = next_time - current_time
</span></span><span class=line><span class=cl>		distances.add(edge.weight + wait_time)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return min(distances)
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><p>\newpage</p><a href=#modified-exact-algorithm-pseudocode><h3 id=modified-exact-algorithm-pseudocode><span class=hanchor arialabel=Anchor># </span>Modified Exact Algorithm Pseudocode</h3></a><p>Below is the final pseudocode for the exact algorithm, based on Held-Karp. A Python implementation of the following pseudocode can be found
<a href=https://github.com/garv-shah/brain/blob/hugo/content/notes/School-Subjects/Algorithmics/SAT/main.py rel=noopener>here</a>.</p><p>Let $A =$ starting vertex
Let $B =$ ending vertex
Let $S = {P, Q, R}$ or any other vertices to be visited along the way.
Let $C \in S$ (random node in $S$)</p><a href=#main-function-1><h4 id=main-function-1><span class=hanchor arialabel=Anchor># </span>Main Function</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function main(
</span></span><span class=line><span class=cl>	friends: dictionary,
</span></span><span class=line><span class=cl>	landmarks: dictionary,
</span></span><span class=line><span class=cl>	routes: dictionary,
</span></span><span class=line><span class=cl>	timetable: dictionary
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	// global variable declarations
</span></span><span class=line><span class=cl>	concession: bool = Ask the user &#34;Do you posses a concession card?&#34;
</span></span><span class=line><span class=cl>	holiday: bool = Ask the user &#34;Is today a weekend or a holiday?&#34;
</span></span><span class=line><span class=cl>	user_name: string = Ask the user to select a friend from friends dictionary
</span></span><span class=line><span class=cl>	selected_time = Ask the user what time they are leaving
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	cached_djk: dictionary = empty dictionary
</span></span><span class=line><span class=cl>	edge_lookup_matrix: matrix = |V| x |V| matrix that stores a list of edges in each entry
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	// get distance of all friends from landmarks
</span></span><span class=line><span class=cl>	friend_distances: dictionary = calculate_nodes(friends, landmarks)
</span></span><span class=line><span class=cl>	visit_set: set = set of all closest nodes from friend_distances
</span></span><span class=line><span class=cl>	people_at_nodes: dictionary = all friends sorted into keys of which nodes they are closest to, from visit_set
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	home: string = closest node of user_name
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print all friends, where they live closest to and how far away
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print out friends that would take more than 20 minutes to walk (average human walking speed is 5.1 km/h)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	hamiltonian_path = fetch_hk(home, home, visit_set, selected_time)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print how much the trip would cost and how long it would take
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print the path of the hamiltonian_path
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#calculate-nodes-1><h4 id=calculate-nodes-1><span class=hanchor arialabel=Anchor># </span>Calculate Nodes</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function calculate_nodes (
</span></span><span class=line><span class=cl>	friend_data: dictionary,
</span></span><span class=line><span class=cl>	node_data: dictionary
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	for friend in friend_data:
</span></span><span class=line><span class=cl>		home: tuple = friend[&#39;home&#39;]
</span></span><span class=line><span class=cl>		// initial min vals that will be set to smallest iterated distance
</span></span><span class=line><span class=cl>		min: float = infinity
</span></span><span class=line><span class=cl>		min_node: node = null
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		for node in node_data:
</span></span><span class=line><span class=cl>			location: tuple = node[&#39;coordinates&#39;]
</span></span><span class=line><span class=cl>			// find real life distance (functional abstraction)
</span></span><span class=line><span class=cl>			distance: float = latlong_distance(home, location)
</span></span><span class=line><span class=cl>			if distance &lt; min:
</span></span><span class=line><span class=cl>				min = distance
</span></span><span class=line><span class=cl>				min_node = node
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		distance_dict[friend][&#39;min_node&#39;] = min_node
</span></span><span class=line><span class=cl>		distance_dict[friend][&#39;distance&#39;] = min
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#held-karp-1><h4 id=held-karp-1><span class=hanchor arialabel=Anchor># </span>Held-Karp</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function held_karp (
</span></span><span class=line><span class=cl>    start: node,
</span></span><span class=line><span class=cl>    end: node,
</span></span><span class=line><span class=cl>    visit: set&lt;node&gt;,
</span></span><span class=line><span class=cl>    current_time: datetime
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>    if visit.size = 0:
</span></span><span class=line><span class=cl>    	djk = fetch_djk(start, end, current_time)
</span></span><span class=line><span class=cl>		return djk[&#39;cost&#39;]
</span></span><span class=line><span class=cl>    else:
</span></span><span class=line><span class=cl>        min = infinity
</span></span><span class=line><span class=cl>        For node C in set S:
</span></span><span class=line><span class=cl>	        sub_path = fetch_hk(start, C, (set \ C), current_time)
</span></span><span class=line><span class=cl>	        djk = fetch_djk(C, end, current_time + toMinutes(sub_path[&#39;cost&#39;]))
</span></span><span class=line><span class=cl>	        cost = sub_path[&#39;cost&#39;] + djk[&#39;cost&#39;]
</span></span><span class=line><span class=cl>	        if cost &lt; min:
</span></span><span class=line><span class=cl>	            min = cost
</span></span><span class=line><span class=cl>	    return min
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#fetch-held-karp-cached><h4 id=fetch-held-karp-cached><span class=hanchor arialabel=Anchor># </span>Fetch Held-Karp (Cached)</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>cached_hk = dictionary of list -&gt; dict
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>function fetch_hk (
</span></span><span class=line><span class=cl>	start: node, 
</span></span><span class=line><span class=cl>	end: node,
</span></span><span class=line><span class=cl>	visit: set of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime,
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	// unique identifier
</span></span><span class=line><span class=cl>	name = start + &#39;-&#39; + end + visit set + &#39;@&#39; + current_time
</span></span><span class=line><span class=cl>	if cached_hk[name] does not exists:
</span></span><span class=line><span class=cl>		cached_hk[name] = held_karp(start, end, visit, current_time)
</span></span><span class=line><span class=cl>	return cached_hk[name]
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#dijkstras-1><h4 id=dijkstras-1><span class=hanchor arialabel=Anchor># </span>Dijkstra&rsquo;s</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function dijkstras (
</span></span><span class=line><span class=cl>    start: node,
</span></span><span class=line><span class=cl>    current_time: datetime
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	unexplored = empty min priority queue of nodes based on distance
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>    // Set all node distance to infinity
</span></span><span class=line><span class=cl>    for node in graph:
</span></span><span class=line><span class=cl>        distance[node] = infinity
</span></span><span class=line><span class=cl>        predecessor[node] = null
</span></span><span class=line><span class=cl>        unexplored.add(node)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    // starting distance has to be 0
</span></span><span class=line><span class=cl>    distance[start] = 0
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    // while more to still explore
</span></span><span class=line><span class=cl>    while unexplored is not empty:
</span></span><span class=line><span class=cl>        min_node = unexplored.minimum_node()
</span></span><span class=line><span class=cl>        unexplored.remove(min_node)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>	    // go through every neighbour and relax
</span></span><span class=line><span class=cl>        for each neighbour of min_node:
</span></span><span class=line><span class=cl>            current_dist = distance[min_node] + dist(min_node, neighbour, current_time + to_minutes(distance[min_node]))
</span></span><span class=line><span class=cl>            // a shorter path has been found to the neighbour -&gt; relax value
</span></span><span class=line><span class=cl>            if current_dist &lt; distance[neighbour]:
</span></span><span class=line><span class=cl>                distance[neighbour] = current_dist
</span></span><span class=line><span class=cl>                predecessor[neighbour] = min_node
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    return {
</span></span><span class=line><span class=cl>	    &#39;distances&#39;: distance,
</span></span><span class=line><span class=cl>	    &#39;predecessors&#39;: predecessor,
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#fetch-dijkstras-cached-1><h4 id=fetch-dijkstras-cached-1><span class=hanchor arialabel=Anchor># </span>Fetch Dijkstra&rsquo;s (Cached)</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>cached_djk = dictionary of node -&gt; dict
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>function fetch_djk (
</span></span><span class=line><span class=cl>    start: node,
</span></span><span class=line><span class=cl>    end: node,
</span></span><span class=line><span class=cl>    current_time: datetime,
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	name = start + &#39;@&#39; + current_time
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>    if cached_djk[name] does not exists:
</span></span><span class=line><span class=cl>        cached_djk[name] = dijkstras(start, current_time)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    djk = cached_djk[name]
</span></span><span class=line><span class=cl>    # reconstructs the path  
</span></span><span class=line><span class=cl>    path = [end] as queue
</span></span><span class=line><span class=cl>    while path.back != start:
</span></span><span class=line><span class=cl>        path.enqueue(djk[&#39;predecessors&#39;][path.back])
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    return {
</span></span><span class=line><span class=cl>        &#39;distance&#39;: djk[&#39;distances&#39;][end],
</span></span><span class=line><span class=cl>        &#39;path&#39;: path
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#distance-function-1><h4 id=distance-function-1><span class=hanchor arialabel=Anchor># </span>Distance Function</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function dist (
</span></span><span class=line><span class=cl>	start: node,
</span></span><span class=line><span class=cl>	end: node,
</span></span><span class=line><span class=cl>	current_time: datetime
</span></span><span class=line><span class=cl>):	
</span></span><span class=line><span class=cl>	// if the start and end node are the same, it takes no time to get there
</span></span><span class=line><span class=cl>	if start = end:
</span></span><span class=line><span class=cl>		return 0
</span></span><span class=line><span class=cl>	else if edges = null:
</span></span><span class=line><span class=cl>		// if no edge exists between nodes
</span></span><span class=line><span class=cl>		return infinity
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	edges = edge_lookup_matrix[start][end]
</span></span><span class=line><span class=cl>	distances = []
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	// go over each possible edge between nodes (multiple possible)
</span></span><span class=line><span class=cl>	for edge in edges:
</span></span><span class=line><span class=cl>		wait_time = wait time from data (precomputed)
</span></span><span class=line><span class=cl>		distances.add(edge.weight + wait_time)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return min(distances)
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><p>\newpage</p><a href=#approximate-algorithm-pseudocode><h3 id=approximate-algorithm-pseudocode><span class=hanchor arialabel=Anchor># </span>Approximate Algorithm Pseudocode</h3></a><p>Below is the final pseudocode for the approximate algorithm, using Simulated Annealing. A Python implementation of the following pseudocode can be found
<a href=https://github.com/garv-shah/brain/blob/hugo/content/notes/School-Subjects/Algorithmics/SAT/main_approximate.py rel=noopener>here</a>.</p><p>Let $A =$ starting vertex
Let $B =$ ending vertex
Let $S = {P, Q, R}$ or any other vertices to be visited along the way.
Let $C \in S$ (random node in $S$)</p><a href=#main-function-2><h4 id=main-function-2><span class=hanchor arialabel=Anchor># </span>Main Function</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function main(
</span></span><span class=line><span class=cl>	friends: dictionary,
</span></span><span class=line><span class=cl>	landmarks: dictionary,
</span></span><span class=line><span class=cl>	routes: dictionary,
</span></span><span class=line><span class=cl>	timetable: dictionary
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	// global variable declarations
</span></span><span class=line><span class=cl>	concession: bool = Ask the user &#34;Do you posses a concession card?&#34;
</span></span><span class=line><span class=cl>	holiday: bool = Ask the user &#34;Is today a weekend or a holiday?&#34;
</span></span><span class=line><span class=cl>	user_name: string = Ask the user to select a friend from friends dictionary
</span></span><span class=line><span class=cl>	selected_time = Ask the user what time they are leaving
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	cached_djk: dictionary = empty dictionary
</span></span><span class=line><span class=cl>	edge_lookup_matrix: matrix = |V| x |V| matrix that stores a list of edges in each entry
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	// get distance of all friends from landmarks
</span></span><span class=line><span class=cl>	friend_distances: dictionary = calculate_nodes(friends, landmarks)
</span></span><span class=line><span class=cl>	visit_set: set = set of all closest nodes from friend_distances
</span></span><span class=line><span class=cl>	people_at_nodes: dictionary = all friends sorted into keys of which nodes they are closest to, from visit_set
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	home: string = closest node of user_name
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print all friends, where they live closest to and how far away
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print out friends that would take more than 20 minutes to walk (average human walking speed is 5.1 km/h)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	candidate = candidate_solution(home, home, visit_set, selected_time)
</span></span><span class=line><span class=cl>	hamiltonian_path = simulated_annealing(candidate[&#39;path&#39;], selected_time)
</span></span><span class=line><span class=cl>	// or hill_climbing(candidate[&#39;path&#39;], selected_time)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	hamiltonian_path[&#39;path&#39;] = normalise_path(hamiltonian_path[&#39;path&#39;], selected_time)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print how much the trip would cost and how long it would take
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	print the path of the hamiltonian_path
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#calculate-nodes-2><h4 id=calculate-nodes-2><span class=hanchor arialabel=Anchor># </span>Calculate Nodes</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function calculate_nodes (
</span></span><span class=line><span class=cl>	friend_data: dictionary,
</span></span><span class=line><span class=cl>	node_data: dictionary
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	for friend in friend_data:
</span></span><span class=line><span class=cl>		home: tuple = friend[&#39;home&#39;]
</span></span><span class=line><span class=cl>		// initial min vals that will be set to smallest iterated distance
</span></span><span class=line><span class=cl>		min: float = infinity
</span></span><span class=line><span class=cl>		min_node: node = null
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		for node in node_data:
</span></span><span class=line><span class=cl>			location: tuple = node[&#39;coordinates&#39;]
</span></span><span class=line><span class=cl>			// find real life distance (functional abstraction)
</span></span><span class=line><span class=cl>			distance: float = latlong_distance(home, location)
</span></span><span class=line><span class=cl>			if distance &lt; min:
</span></span><span class=line><span class=cl>				min = distance
</span></span><span class=line><span class=cl>				min_node = node
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		distance_dict[friend][&#39;min_node&#39;] = min_node
</span></span><span class=line><span class=cl>		distance_dict[friend][&#39;distance&#39;] = min
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#candidate-solution-nn-heuristic><h4 id=candidate-solution-nn-heuristic><span class=hanchor arialabel=Anchor># </span>Candidate Solution (NN Heuristic)</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>// creates a canditate solution using the NN Heuristic
</span></span><span class=line><span class=cl>function canditate_solution (
</span></span><span class=line><span class=cl>	start: node, 
</span></span><span class=line><span class=cl>	end: node,
</span></span><span class=line><span class=cl>	visit: set of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime,
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	path = [start]
</span></span><span class=line><span class=cl>	current_vertex = start
</span></span><span class=line><span class=cl>	cost = 0
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	while len(visit) != 0:
</span></span><span class=line><span class=cl>		closest_node = fetch_djk(current_vertex, visit, current_time)
</span></span><span class=line><span class=cl>		path.add(closest_node)
</span></span><span class=line><span class=cl>		cost += closest_node.cost
</span></span><span class=line><span class=cl>		visit.remove(closest_node)
</span></span><span class=line><span class=cl>		current_vertex = closest_node
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	// go back to the end node
</span></span><span class=line><span class=cl>	closest_node = fetch_djk(current_vertex, end, current_time)
</span></span><span class=line><span class=cl>	path.add(closest_node)
</span></span><span class=line><span class=cl>	cost += closest_node.cost
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return {&#39;path&#39;: path, &#39;cost&#39;: cost}
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#pairwise-swap><h4 id=pairwise-swap><span class=hanchor arialabel=Anchor># </span>Pairwise Swap</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function pairwise_swap (
</span></span><span class=line><span class=cl>	u: integer,
</span></span><span class=line><span class=cl>	v: integer,
</span></span><span class=line><span class=cl>	path: path of nodes
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	new_tour = []
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	for i in [0, u]:
</span></span><span class=line><span class=cl>		new_tour.add(path[i])
</span></span><span class=line><span class=cl>	for i in [v, u):
</span></span><span class=line><span class=cl>		new_tour.add(path[i])
</span></span><span class=line><span class=cl>	for i in (v, len(path)]:
</span></span><span class=line><span class=cl>		new_tour.add(path[i])
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return new_tour
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#calculate-cost><h4 id=calculate-cost><span class=hanchor arialabel=Anchor># </span>Calculate Cost</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function calculate_cost (
</span></span><span class=line><span class=cl>	path: path of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	cost = 0
</span></span><span class=line><span class=cl>	time = current_time
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	for i from 0 to len(path) - 1:
</span></span><span class=line><span class=cl>		djk = fetch_djk(path[i], path[i + 1], current_time)
</span></span><span class=line><span class=cl>		cost += djk[&#39;cost&#39;]
</span></span><span class=line><span class=cl>		time += djk[&#39;cost&#39;] number of minutes
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return cost
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#hill-climbing><h4 id=hill-climbing><span class=hanchor arialabel=Anchor># </span>Hill Climbing</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function hill_climbing (
</span></span><span class=line><span class=cl>	candidate: path of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime,
</span></span><span class=line><span class=cl>	fail_count: int = 0
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	if fail_count &lt; 200:
</span></span><span class=line><span class=cl>		cost = calculate_cost(candidate, current_time)
</span></span><span class=line><span class=cl>		u = random number from 1 to len(candidate) - 1 inclusive
</span></span><span class=line><span class=cl>		v = random number from u to len(candidate) - 1 inclusive
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		new_tour = pairwise_swap(u, v, candidate)
</span></span><span class=line><span class=cl>		new_cost = calculate_cost(new_tour, current_time)
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>		if new_cost &lt;= cost:
</span></span><span class=line><span class=cl>			// new cost is better/equal -&gt; accept
</span></span><span class=line><span class=cl>			return hill_climbing(new_tour, current_time, 0)
</span></span><span class=line><span class=cl>		else:
</span></span><span class=line><span class=cl>			// new cost is worse -&gt; go again
</span></span><span class=line><span class=cl>			return hill_climbing(candidate, current_time, fail_count + 1)
</span></span><span class=line><span class=cl>	else:
</span></span><span class=line><span class=cl>		return candidate
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#simulated-annealing-1><h4 id=simulated-annealing-1><span class=hanchor arialabel=Anchor># </span>Simulated Annealing</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function simulated_annealing (
</span></span><span class=line><span class=cl>	candidate: path of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime,
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	// parameters to fiddle with
</span></span><span class=line><span class=cl>	temp = 0.98
</span></span><span class=line><span class=cl>	min_temp = 0.00001
</span></span><span class=line><span class=cl>	temp_change = 5
</span></span><span class=line><span class=cl>	beta = 1.2
</span></span><span class=line><span class=cl>	alpha = 0.85
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	old_cost = calculate_cost(candidate, current_time)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	while temp &gt; min_temp:
</span></span><span class=line><span class=cl>		for n from 1 to temp_change:
</span></span><span class=line><span class=cl>			u = random number from 1 to len(candidate) - 1 inclusive
</span></span><span class=line><span class=cl>			v = random number from u to len(candidate) - 1 inclusive
</span></span><span class=line><span class=cl>			
</span></span><span class=line><span class=cl>			new_tour = pairwise_swap(u, v, candidate)
</span></span><span class=line><span class=cl>			new_cost = calculate_cost(new_tour, current_time)
</span></span><span class=line><span class=cl>			
</span></span><span class=line><span class=cl>			ap = acceptance_probability(old_cost, new_cost, beta, temp)
</span></span><span class=line><span class=cl>			
</span></span><span class=line><span class=cl>			if ap &gt; random float from 0 to 1:
</span></span><span class=line><span class=cl>				candidate = new_tour
</span></span><span class=line><span class=cl>				old_cost = new_cost
</span></span><span class=line><span class=cl>			
</span></span><span class=line><span class=cl>		temp *= alpha
</span></span><span class=line><span class=cl>		
</span></span><span class=line><span class=cl>	return candidate
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#acceptance-probability><h4 id=acceptance-probability><span class=hanchor arialabel=Anchor># </span>Acceptance Probability</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function acceptance_probability (
</span></span><span class=line><span class=cl>	old_cost: number,
</span></span><span class=line><span class=cl>	new_cost: number,
</span></span><span class=line><span class=cl>	beta: number,
</span></span><span class=line><span class=cl>	temp: number
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	c = new_cost - old_cost
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	if c &lt;= 0:
</span></span><span class=line><span class=cl>		return 1
</span></span><span class=line><span class=cl>	else:
</span></span><span class=line><span class=cl>		return e**((-beta * c)/temp)
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#dijkstras-2><h4 id=dijkstras-2><span class=hanchor arialabel=Anchor># </span>Dijkstra&rsquo;s</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function dijkstras (
</span></span><span class=line><span class=cl>    start: node,
</span></span><span class=line><span class=cl>    current_time: datetime
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	unexplored = empty min priority queue of nodes based on distance
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>    // Set all node distance to infinity
</span></span><span class=line><span class=cl>    for node in graph:
</span></span><span class=line><span class=cl>        distance[node] = infinity
</span></span><span class=line><span class=cl>        predecessor[node] = null
</span></span><span class=line><span class=cl>        unexplored.add(node)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    // starting distance has to be 0
</span></span><span class=line><span class=cl>    distance[start] = 0
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    // while more to still explore
</span></span><span class=line><span class=cl>    while unexplored is not empty:
</span></span><span class=line><span class=cl>        min_node = unexplored.minimum_node()
</span></span><span class=line><span class=cl>        unexplored.remove(min_node)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>	    // go through every neighbour and relax
</span></span><span class=line><span class=cl>        for each neighbour of min_node:
</span></span><span class=line><span class=cl>            current_dist = distance[min_node] + dist(min_node, neighbour, current_time + to_minutes(distance[min_node]))
</span></span><span class=line><span class=cl>            // a shorter path has been found to the neighbour -&gt; relax value
</span></span><span class=line><span class=cl>            if current_dist &lt; distance[neighbour]:
</span></span><span class=line><span class=cl>                distance[neighbour] = current_dist
</span></span><span class=line><span class=cl>                predecessor[neighbour] = min_node
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    return {
</span></span><span class=line><span class=cl>	    &#39;distances&#39;: distance,
</span></span><span class=line><span class=cl>	    &#39;predecessors&#39;: predecessor,
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#fetch-dijkstras-cached-2><h4 id=fetch-dijkstras-cached-2><span class=hanchor arialabel=Anchor># </span>Fetch Dijkstra&rsquo;s (Cached)</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>cached_djk = dictionary of node -&gt; dict
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>function fetch_djk (
</span></span><span class=line><span class=cl>    start: node,
</span></span><span class=line><span class=cl>    end: node,
</span></span><span class=line><span class=cl>    current_time: datetime,
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	name = start + &#39;@&#39; + current_time
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>    if cached_djk[name] does not exists:
</span></span><span class=line><span class=cl>        cached_djk[name] = dijkstras(start, current_time)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    djk = cached_djk[name]
</span></span><span class=line><span class=cl>    # reconstructs the path  
</span></span><span class=line><span class=cl>    path = [end] as queue
</span></span><span class=line><span class=cl>    while path.back != start:
</span></span><span class=line><span class=cl>        path.enqueue(djk[&#39;predecessors&#39;][path.back])
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    return {
</span></span><span class=line><span class=cl>        &#39;distance&#39;: djk[&#39;distances&#39;][end],
</span></span><span class=line><span class=cl>        &#39;path&#39;: path
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#distance-function-2><h4 id=distance-function-2><span class=hanchor arialabel=Anchor># </span>Distance Function</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function dist (
</span></span><span class=line><span class=cl>	start: node,
</span></span><span class=line><span class=cl>	end: node,
</span></span><span class=line><span class=cl>	current_time: datetime
</span></span><span class=line><span class=cl>):	
</span></span><span class=line><span class=cl>	// if the start and end node are the same, it takes no time to get there
</span></span><span class=line><span class=cl>	if start = end:
</span></span><span class=line><span class=cl>		return 0
</span></span><span class=line><span class=cl>	else if edges = null:
</span></span><span class=line><span class=cl>		// if no edge exists between nodes
</span></span><span class=line><span class=cl>		return infinity
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	edges = edge_lookup_matrix[start][end]
</span></span><span class=line><span class=cl>	distances = []
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	// go over each possible edge between nodes (multiple possible)
</span></span><span class=line><span class=cl>	for edge in edges:
</span></span><span class=line><span class=cl>		wait_time = wait time from data (precomputed)
</span></span><span class=line><span class=cl>		distances.add(edge.weight + wait_time)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return min(distances)
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><a href=#normalising-function-1><h4 id=normalising-function-1><span class=hanchor arialabel=Anchor># </span>Normalising Function</h4></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>function normalise_path (
</span></span><span class=line><span class=cl>	path: path of nodes,
</span></span><span class=line><span class=cl>	current_time: datetime
</span></span><span class=line><span class=cl>):
</span></span><span class=line><span class=cl>	return_path = []
</span></span><span class=line><span class=cl>	time = current_time
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	for i from 0 to len(path) - 1:
</span></span><span class=line><span class=cl>		djk = fetch_djk(path[i], path[i + 1], current_time)
</span></span><span class=line><span class=cl>		time += djk[&#39;cost&#39;] number of minutes
</span></span><span class=line><span class=cl>		// this is to prevent the last and first item double up
</span></span><span class=line><span class=cl>		return_path += everything in djk[&#39;path&#39;] except last item
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return_route.add(last item in route)
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	return cost
</span></span><span class=line><span class=cl>end function
</span></span></code></pre></td></tr></table></div></div><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>This rule is not often used, but $\beta$ is a different constant that we&rsquo;ll get to later.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://quartz.jzhao.xyz/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Garv Shah using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2023</p><ul><li><a href=https://quartz.jzhao.xyz/>Home</a></li><li><a href=https://www.linkedin.com/in/garvshah/>LinkedIn</a></li><li><a href=https://github.com/garv-shah>GitHub</a></li></ul></footer></div></div></body></html>